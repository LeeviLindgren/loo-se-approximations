\documentclass{article}
\usepackage{geometry}
 \geometry{
 a4paper,
 %total={170mm,257mm},
 %left=25.4mm,
 %top=25.4mm,
 %bottom=25.4mm,
 %right=25.4mm,
 }

\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsthm,amssymb,graphicx,mathtools,tikz,hyperref}
\usepackage[round]{natbib}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[section]{placeins}

\newcommand{\residual}[2][i]{\hat{e}_{#1}^{(#2)}}

\graphicspath{ {../figures/} }

\title{Analytical approximations for leave one out utility standard errors}
\author{Leevi Lindgren \footnote{I thank Aki Vehtari and Nikolas Siccha for their comments.}}
\date{\today}

\begin{document}

\maketitle

\clearpage
\section*{Note}

The approach in this report was motivated by the work by \cite{hastings1970monte} who proposes an approximation for the variance of the ratio of two random variables. However, the formula provided by \cite{hastings1970monte} contains two typos: on page 8, in the formula for the variance of the ratio, $\bar{Z}$ is missing the "bar" symbol and computed variance $s_{\bar{Z}}$ is missing the second power. The missing second power caused the author of this report to mistake it for the standard deviation instead of variance, which was followed by weird simulation results. Unfortunately, research papers are not like software: you cannot make a pull request to fix a bug.
\clearpage

\tableofcontents
\clearpage
\section{Introduction}

This report presents analytical approximations for standard errors of different predictive metrics in the context of Bayesian predictive model assessment. 

Usefulness of a statistical model is often evaluated by assessing the predictive performance of the model. Significant discrepancies between the predicted values and observations suggest that the model is not useful, even though the ultimate goal is to make inference in some parameter, such as treatment effect. There is a major challenge when evaluating the predictive power: future observations are not available.

Predictive performance of a statistical model is hence estimated as the expected predictive predictive performance (or utility). 

Introduce LOO

Discuss comparison using LOO utilities

Discuss the uncertainty evaluation of the estimation. Why this analytical approximation approach would be useful (compared to e.g. BB)?

The report is structured as follows: The second section follows closely the ideas presented in \cite{vehtari_survey_2012} and introduces briefly some theory on model assessment and comparison based on predictive performance. Third section presents Taylor approximation for functions of two variables, and shows how expectations and variances can be approximated when the variables are considered to be random. Four section discusses X different metrics and the analytical formulas for the variance of the estimator. Moreover, approximation of variance of the difference between two estimators is also represented. In section five, we verify the validity of the approximations with simulation studies. Finally, the last section provides concluding remarks.

\section{Predictive methods for Bayesian model assessment}
This section reviews three concepts central to the later discussion in the paper: 1) estimating the predictive performance of a statistical model 2) comparing statistical models and 3) quantifying the uncertainty in the performance estimates. We follow closely the ideas from \cite{vehtari_survey_2012}. Notation through out this report, and specifically this section, is summarized in Table  \ref{tab:notation}.

\subsection{Estimating the predictive performance}
As noted in the first section, the usefulness of a statistical model is often evaluated on the basis of predictive performance. Performance is measured by some utility function $u$. Formally, the expected predictive performance for utility $u$ can be written as 
\begin{equation}
u(M_k | y) = \int u(M_k, \hat{a}_k, \tilde{y} | y) p_t(\tilde{y}) d\tilde{y}, \label{eq:true-utility}
\end{equation}
where $\hat{a}_k$ denotes the optimal decision under $M_k$. For example, if the defined utility is mean squared error (MSE), the optimal decision, or prediction, is using the posterior predictive expectation of $\tilde{y}$, i.e., $E\left[ \tilde{y} | y, M_k \right]$. Then Equation \eqref{eq:true-utility} for MSE can be written as
$$
u_{\text{MSE}}(M_k | y) = \int \left( \tilde{y} - E\left[ \tilde{y} | y, M_k \right] \right)^2 p_t(\tilde{y}) d\tilde{y}
$$

Computing \eqref{eq:true-utility} poses a challenge as we rarely know the true mechanism which generates the data, $p_t(y)$. In optimal case we would have independent test data $\tilde{y}_i, i=1,...,\tilde{n}$ and \eqref{eq:true-utility} would be easy to compute using
\begin{equation}
    \hat{u}_{\text{test}}(M_k | y) = \frac{1}{\tilde{n}} \sum_{i=1}^{\tilde{n}} u(M_k, \hat{a}_k, \tilde{y}_i | y). \label{eq:test-utility}
\end{equation}
However, typically we don't have access to such data.

To tackle this, naive approach would be to re-use the observed data which was used to train the model, and compute "training" version of \eqref{eq:true-utility}:
\begin{equation}
    \hat{u}_{\text{train}}(M_k | y) = \frac{1}{n} \sum_{i=1}^n u(M_k, \hat{a}_k, y_i | y). \label{eq:train-utility}
\end{equation}
Training utility in \eqref{eq:train-utility} is a biased estimate of \eqref{eq:true-utility}, and typically is over optimistic about the predictive performance of the model.

One way to improve the quality of the training utility estimate is to introduce a sample re-use strategy in which data is split into folds $I_1, ..., I_K$ and each dataset $y_{I_k}$ is used in turn as a validation set, while model is trained with $y_{-I_k}$. This approach is called cross-validation (CV). Special case of CV is leave-one-out corr-validation (LOO-CV), where data of size $n$ is split into $n$ folds. LOO-CV utility estimate is then given as 
\begin{equation}
    \hat{u}_{\text{LOO}}(M_k | y) = \frac{1}{n} \sum_{i = 1}^n u(M_k, \hat{a}_k, y_i | y_{-i}) \label{eq:loo-utility}.
\end{equation}

\subsection{Model comparison}
Typically in Bayesian workflow, the modeller has multiple candidate models. If model averaging is not possible or the set of candidate models need to be thinned, e.g. due to the cost of data gathering, she would like to choose one model from the set of candidates. The goal is to choose model having the best expected utility.

Ideas from the previous section can be extended into the context of model comparison. Consider two models, $M_A$ and $M_B$. With a slight use of notation, we write the difference on the expected utility between models A and B as
\begin{align}
    u(M_A, M_B | y) &= u(M_A | y) - u(M_B | y) \nonumber \\ 
    &= \int u(M_A, \hat{a}_k, \tilde{y} | y) p_t(\tilde{y}) d\tilde{y} - \int u(M_B, \hat{a}_k, \tilde{y} | y) p_t(\tilde{y}) d\tilde{y} \nonumber \\
    &= \int \left( u(M_A, \hat{a}_k, \tilde{y} | y) - u(M_B, \hat{a}_k, \tilde{y} | y) \right) p_t(\tilde{y}) d\tilde{y} \label{eq:true-diff}
\end{align}

Following the ideas from the previous section, we can compute the estimators for the difference in utilities given e.g. independent test data, training data or LOO re-use of data. As we will focus on LOO estimators in the following sections, we only state LOO estimator for the difference. We use the definitions by \cite{vehtari_practical_2016} and \cite{sivula_uncertainty_2022}:
\begin{align}
    \hat{u}_{\text{LOO}}(M_A, M_B | y) &= \frac{1}{n} \sum_{i=1}^n u(M_A, \hat{a}_k, y_i | y_{-i}) - \frac{1}{n} \sum_{i=1}^n u(M_A, \hat{a}_k, y_i | y_{-i}) \nonumber \\
    &:= \frac{1}{n}\sum_{i=1}^n u(M_A, M_B, y_i | y_{-i}) \label{eq:loo-diff}.
\end{align}


\subsection{Assessing the uncertainty of the estimators}
If we knew $p_t(y)$, we could compute the quantity \eqref{eq:true-utility} with arbitrary accuracy. Alternatively, if we had an independent test dataset, then the uncertainty could be quantified with the Monte Carlo standard error of \eqref{eq:test-utility}. Moreover, if the variance of the individual components $\hat{u}_{\text{test}}(M_k, \hat{a}_k, \tilde{y}_i | y)$ is finite, the error distribution will converge towards normal distribution. 

Following \cite{vehtari_practical_2016} and \cite{sivula_uncertainty_2022}, we can compute Monte Carlo error of \eqref{eq:loo-utility} and \eqref{eq:loo-diff} in a similar way, by considering the individual terms in the corresponding sums. These Monte Carlo error estimates describe the \textit{epistemic} uncertainty about the true values \eqref{eq:true-utility} and \eqref{eq:true-diff}, arising due to the fact that we are working with finite data. (NOTE: check if this is correct)

Variance of the estimator is
\begin{align}
    \text{var} \left( \hat{u}_{\text{LOO}}(M_k | y) \right)  &= \frac{1}{n-1} \sum_{i = 1}^n \left( \hat{u}_{\text{LOO}}(M_k, y_i | y_{-i}) -  \frac{1}{n} \sum_{i=1}^n \hat{u}_{\text{LOO}}(M_k, y_i | y_{-i}) \right)^2, \label{eq:var-loo}
\end{align}
and the variance of the difference \eqref{eq:loo-diff}:
\begin{align}
    \text{var} \left( \hat{u}_{\text{LOO}}(M_A, M_B | y) \right) &= \frac{1}{n-1} \sum_{i = 1}^n \left( \hat{u}_{\text{LOO}}(M_A, M_B, y_i | y_{-i}) -  \frac{1}{n} \sum_{i=1}^n \hat{u}_{\text{LOO}}(M_A, M_B, y_i | y_{-i}) \right)^2. \label{eq:var-loo-diff}
\end{align}
When estimating LOO utilities, \cite{sivula_uncertainty_2022} note that these naive variance estimators are typically biased since the individual LOO terms are not independent in general.

For particular utilities, such root mean squared error (RMSE) and (Bayesian) R-squared, we "loose" the information of individual terms. Take the RMSE as an example. It is defined as the square root of the mean squared error, so we don't have the individual utility terms $u(M_k, \hat{a}_k, y_i | \cdot)$ to work with. In these cases, the uncertainty could be quantified by methods such as Bayesian bootstrap (BB) (\cite{rubin_bayesian_1981}, \cite{vehtari_bayesian_2002}, \cite{vehtari_survey_2012}). We propose an analytical approximation making use of Taylor expansions of functions of random variables. 

In the upcoming sections, we demonstrate how Taylor expansions can be used to obtain analytical approximations of the variance estimators in cases when it is not possible to compute \eqref{eq:var-loo} or \eqref{eq:var-loo-diff} directly. 

\begin{table}[!htb]
    \centering
    \begin{tabular}{l | p{0.8\linewidth}}
    \toprule
        notation & meaning \\ \midrule
        $p_t(\tilde{y})$ & The "true" data generating distribution, which is typically unknown. \\
        $y_i | y_{-i}$ & $y_i$ given all other observations than $y_i$. E.g. $p(y_i | y_{-i})$ denotes the leave one out predictive distribution of $y_i$. \\
        $ u(M_k | y) $ & Utility for model $M_k$ with respect to the true data generating process given the observed data $y_i$. \\
        $u(M_k, y_i | y)$ & Utility for a single data point, if applicable
        
    \end{tabular}
    \caption{Notation used throughout the paper.}
    \label{tab:notation}
\end{table}

\section{Taylor series approximations}
Taylor series of a function is a infinite sum in which each term is a partial derivative of increasing order. Function value at a particular point and the value of the Taylor series sum coincide at that point. By truncating the Taylor sum, one obtains approximations of a function around some point. Perhaps the most common approximations are the first order (linear) and second order approximations.

First order Taylor approximation of a function $f: \mathbb{R} \rightarrow \mathbb{R}$ of a single variable around point $x_0$ is
\begin{equation*}
    f(x) \approx f(x_0) + \frac{\partial f}{\partial x}(x)(x-x_0) \label{eq:tapprox1d}.
\end{equation*}

Bivariate case is similar. Let $f(x, y): \mathbb{R}^2 \rightarrow \mathbb{R}$ be a function of two (random) variables. The first order Taylor approximation of a function of two variables around point $x_0, y_0$ is given by
\begin{align*}
    f(x, y) &\approx f(x_0, y_0) + \frac{\partial }{\partial x} f(x_0, y_0) (x - x_0) + \frac{\partial }{\partial y} f(x_0, y_0) (y - y_0) \label{eq:tapprox2d}
\end{align*}

Now, let's take a random variable $X$ and approximate $f: \mathbb{R} \rightarrow \mathbb{R}$ around the expected value of $X$, $\mu_X$:
\begin{equation}
    f(X) \approx f(\mu_X) + \frac{\partial f}{\partial x}(X)(X-\mu_X) \label{eq:rvtapprox1d}.
\end{equation}

With two random variables $X$ and $Y$ and the approximation around the expected values $(\mu_X, \mu_Y)$ = $(E[X], E[Y])$, we get
\begin{align}
    f(X, Y) \approx f(\mu_X, \mu_Y) + \frac{\partial }{\partial x} f(\mu_X, \mu_Y) (X - \mu_X) + \frac{\partial }{\partial y} f(\mu_X, \mu_Y) (Y - \mu_Y) \label{eq:rvtapprox2d}.
\end{align}

\subsection{Taylor approximation for the expected value}
Given that terms containing partial derivatives in \eqref{eq:rvtapprox2d} go to zero under expectation, we get the following, simple, first order approximation for the expected value of $f(X, Y)$:
\begin{align}
    E[f(X, Y)] \approx f(\mu_X, \mu_Y) \label{eapprox}
\end{align}

\subsection{Taylor approximation for variance}
For variance
\begin{align}
    \text{var}(f(X)) &= E\left[ \left(f(X) - E[f(X)] \right)^2 \right] \nonumber \\
    &\approx E\left[ \left( f(X) - f(\mu_X) \right)^2 \right] \nonumber
\end{align}

and
\begin{align}
    \text{var}(f(X, Y)) &= E\left[ \left(f(X, Y) - E[f(X,Y)] \right)^2 \right] \nonumber \\
    &\approx E\left[ \left( f(X, Y) - f(\mu_X, \mu_Y) \right)^2 \right] \nonumber.
\end{align}
Using \eqref{eq:rvtapprox1d}, Taylor approximation for the variance of a function of single random variable is then (we write $\frac{\partial }{\partial x} f(\mu_X) = \frac{\partial f}{\partial x}$ for notational simplicity):
\begin{align}
    \text{var}(f(X)) &\approx E\left[ \left( f(X) - f(\mu_X) \right)^2 \right] \nonumber \\
    &\approx E\left[ \left( \frac{\partial f}{\partial x} \right)^2 (X - \mu_X) \right] \nonumber \\
    &= \left( \frac{\partial f}{\partial x} \right)^2 \text{var}(X) \label{eq:varapprox1d}
\end{align}

Next, we use \eqref{eq:rvtapprox2d} for $f(X,Y)$ which yields
\begin{align}
    \text{var}(f(X, Y)) &\approx E\left[ \left( \frac{\partial f}{\partial x} (X - \mu_X) + \frac{\partial f}{\partial y} (Y - \mu_Y) \right)^2 \right] \nonumber \\
    &= E\left[ \left( \frac{\partial f}{\partial x}  \right)^2 (X - \mu_X)^2 + 2 \frac{\partial f}{\partial x} \frac{\partial f}{\partial y} (X - \mu_X)(Y - \mu_Y) + \left( \frac{\partial f}{\partial y}  \right)^2 (Y - \mu_Y)^2  \right] \nonumber \\
    &= \left( \frac{\partial f}{\partial x}  \right)^2 \text{var}(X) + 2 \frac{\partial f}{\partial x} \frac{\partial f}{\partial y} \text{cov}(X, Y) + \left( \frac{\partial f}{\partial y}  \right)^2 \text{var}(Y). \label{eq:varapprox2d}
\end{align}

\section{Approximations for standard errors of LOO utilities}
In what follows, we consider a general setting, where we have $n$ observations $(y_i, x_i)$ in which $x_i \in \mathbb{R}^p$ and $y_i \in \mathbb{R}$. We are estimating some utility $u(M_k | y)$ with $\hat{u}(M_k |y)$ computed from the training data, using LOO or some approximation of LOO, e.g. Pareto smoothed importance sampling LOO estimator (\cite{vehtari_practical_2016}).

\begin{table}[!htb]
    \centering
    \begin{tabular}{l c c p{0.4\linewidth}}
    \toprule
    $u(M | y)$ & $\widehat{Var}(u)$  & $\widehat{Var}(u(M_A, M_B))$ & Comment \\ \midrule
    MSE & \eqref{eq:var-loo-mse} &  & Needed for the Taylor approximation\\
    RMSE  & \eqref{eq:var-loo-rmse} & \eqref{eq:var-loo-rmse-diff} & RMSE is expressed in terms of MSE\\
    $R^2$ & \eqref{eq:var-loo-r2} & ?? & $R^2$ is expressed in terms of ratio of two mean squared errors and Taylor approximation is used.
    \end{tabular}
    \caption{Taylor approximations for the standard error estimators of different utilities. The middle column refers to the equation of standard error estimator. The equations for standard error estimator for the difference between two utilities are reported in the right-most column.}
    \label{tbl:se-approximations}
\end{table}

%\subsection{Mean absolute error}
%\begin{equation}
%    u(M_k | y)_{\text{MAE}} = \int \left| \tilde{y} - E\left[ \tilde{y} \right| y, M_k \right] | p_t(\tilde{y}) d\tilde{y}.
%\end{equation}
%We can estimate this quantity by in-sample estimator
%\begin{equation}
%    \hat{u}(M_k | y)_{\text{MAE}} = \frac{1}{n} \sum_{i=1}^n \left| y_i - E\left[ y_i | y, M_k \right] \right|,
%\end{equation}
%or by leave-one-out estimator
%\begin{equation}
%    \hat{u}(M_k | y)_{\text{LOO-MAE}} = \frac{1}{n} \sum_{i=0}^n \left| y_i - E\left[ y_i | y_{-i}, M_k \right] \right|
%\end{equation}

\subsection{Mean squared error}
Mean squared error (MSE) is a well known metric from the point estimation literature. It also turns out, that we can express other utilities (root mean squared error and R-squared) and their standard error estimators in terms of mean squared error. This is also case for the variance of the difference. Hence we need to have estimator for the MSE and variance for that estimator.

For notational simplicity, we define the squared residual $\residual{k} := (y_i - E[y_i | y, M_k])^2$ and LOO-residual $\residual[i, loo]{k} := (y_i - E[y_i | y_{-i}, M_k])^2$. MSE is simply defined as
\begin{equation}
    u_{\text{MSE}}(M_k | y) = \int \left( \tilde{y} - E\left[ \tilde{y} | y, M_k \right] \right)^2 p_t(\tilde{y}) d\tilde{y}.
\end{equation}
We can estimate this quantity by in-sample estimator
\begin{align}
    \hat{u}_{\text{MSE}}(M_k | y) &= \frac{1}{n} \sum_{i=1}^n \hat{u}_{\text{MSE}}(M_k, y_i | y) \nonumber \\ 
    &= \frac{1}{n} \sum_{i=1}^n \residual{k}
\end{align}
or by leave-one-out estimator
\begin{align}
    \hat{u}_{\text{LOO-MSE}}(M_k | y) &=\frac{1}{n} \sum_{i=1}^n \hat{u}_{\text{LOO-MSE}}(M_k, y_i | y_{-i}) \nonumber \\
    &=\frac{1}{n} \sum_{i=0}^n \residual[i,loo]{k}. \label{eq:loo-mse}
\end{align}
Using \eqref{eq:var-loo}, we write the variance of the estimator \eqref{eq:loo-mse} as
\begin{align}
    \widehat{\text{var}}\left( \hat{u}_{\text{LOO-MSE}}(M_k | y) \right) &= \frac{1}{n-1} \sum_{i = 1}^n \left( \residual[i, loo]{k} -  \frac{1}{n} \sum_{i=1}^n \residual[i, loo]{k} \right)^2 \label{eq:var-loo-mse}.
\end{align}
In-sample estimator would be computed analogically. 

%For the computation of the estimators of the difference between MSE-LOO and variance of the difference, we use \eqref{eq:loo-diff} and %\eqref{eq:var-loo-diff}. First define $\hat{e}_i^{(k)} := (y_i - E[y_i | y_{-i}, M_k])^2$ as the ith squared LOO residual of model k. Then:
%\begin{align}
%    \hat{u}_{\text{LOO-MSE}}(M_A, M_B | y) &= \frac{1}{n}\sum_{i=1}^n \left( \hat{e}_i^{(A)} - \hat{e}_i^{(B)} \right) \label{eq:loo-diff-mse}
%\end{align}
%\begin{align}
    %\widehat{\text{var}}\left( \hat{u}_{\text{LOO-MSE}}(M_A, M_B | y) \right) = \frac{1}{n-1} \sum_{i=1}^n \left( \left( \hat{e}_i^{(A)} %\hat{e}_i^{(B)} \right) - \frac{1}{n}\sum_{i=1}^n \left( \hat{e}_i^{(A)} - \hat{e}_i^{(B)} \right) \right)^2
% \label{eq:var-loo-diff-mse}
%\end{align}

\subsection{Root mean squared error}
Root mean squared error is simply defined as the square root of MSE and the estimator is, not surprisingly, the square root of MSE estimator in \eqref{eq:loo-mse}:
\begin{equation*}
    \hat{u}_{\text{LOO-RMSE}}(M_k|y) = \sqrt{\hat{u}_{\text{LOO-MSE}}(M_k|y)}.
\end{equation*}
As RMSE can be interpreted as a function of MSE, we can use the Taylor method to approximate the variance of the estimator. Following the previous section, the variance of function $f(x)$ can be expressed in terms of variance of $X$. First, we need the derivative of the function $f(x)= \sqrt{x}$, which is obviously
$$
\frac{\partial f}{\partial x} = \frac{1}{2 \sqrt{x}}.
$$
Variance of the such function is then approximated by \eqref{eq:varapprox1d}:
\begin{align*}
    \text{var}(f(X)) \approx \frac{\text{var}(X)}{4 \sqrt{\mu_X}}.
\end{align*}
Since RMSE is a function of MSE, we can plug in estimator and variance of that estimate into $\mu_X$ and $\text{var}(X)$ to obtain an approximation of the variance of the RMSE estimator:
\begin{equation}
    \widehat{\text{var}} \left( \hat{u}_{\text{LOO-RMSE}}(M_k|y) \right) :=  \frac{\widehat{\text{var}}\left( \hat{u}_{\text{LOO-MSE}}(M_k | y) \right)}{4 \hat{u}_{\text{LOO-MSE}}(M_k | y)} \label{eq:var-loo-rmse}
\end{equation}

If we want to compare two models based on RMSE we want to quantify the uncertainty in the comparison. Variance of the RMSE difference between two models can be also approximated using the same trick. Now we have a function of two random variables
$$
f(x,y) = \sqrt{x} - \sqrt{y}.
$$
The partials are
\begin{align*}
    \frac{\partial f}{\partial x} &= \frac{1}{2 \sqrt{x}} \\
    \frac{\partial f}{\partial y} &= -\frac{1}{2 \sqrt{y}},
\end{align*}
and plugging these into \eqref{eq:varapprox2d} yields\footnote{Recall that \eqref{eq:varapprox2d} is the first order Taylor approximation of the variance around the expected values of $X$ and $Y$}
\begin{align*}
    \text{var}\left(f(X,Y)\right) \approx \frac{\text{var}(X)}{4\sqrt{\mu_X}} - \frac{\text{cov}(X,Y)}{2 \sqrt{\mu_X} \sqrt{\mu_Y}} + \frac{\text{var}(Y)}{4\sqrt{\mu_Y}}.
\end{align*}

\begin{equation}
\begin{aligned}
\widehat{\text{var}} \left( \hat{u}_{\text{LOO-RMSE}}(M_A, M_B | y) \right) &:=  \frac{\hat{\sigma}^2_{\text{MSE}_A}}{4\sqrt{\hat{\mu}_{\text{MSE}_A}}} - 
\frac{\text{cov}(\hat{\mu}_{\text{MSE}_A},\hat{\mu}_{\text{MSE}_B})}{2 \sqrt{\hat{\mu}_{\text{MSE}_A}} \sqrt{\hat{\mu}_{\text{MSE}_B}}} + 
\frac{\hat{\sigma}^2_{\text{MSE}_B}}{4\sqrt{\hat{\mu}_{\text{MSE}_B}}} \\
\hat{\mu}_{\text{MSE}_A} &= \hat{u}_{\text{LOO-MSE}}(M_A | y)\\
\hat{\mu}_{\text{MSE}_B} &= \hat{u}_{\text{LOO-MSE}}(M_B | y)\\
\hat{\sigma}^2_{\text{MSE}_A} &= \widehat{\text{var}}\left(\hat{u}_{\text{LOO-MSE}}(M_A | y)\right) \\
\hat{\sigma}^2_{\text{MSE}_B} &= \widehat{\text{var}}\left(\hat{u}_{\text{LOO-MSE}}(M_B | y)\right) \\
\text{cov}(\hat{\mu}_{\text{MSE}_A},\hat{\mu}_{\text{MSE}_B}) &= \frac{1}{n -1 } \sum_{i = 1}^n \left( \left( \residual[i,loo]{A} - \frac{1}{n} \sum_{i=1}^n \residual[i,loo]{A} \right) \left( \residual[i,loo]{B} - \frac{1}{n} \sum_{i=1}^n \residual[i,loo]{B} \right) \right)
\end{aligned}\label{eq:var-loo-rmse-diff}
\end{equation}
%\frac{\widehat{\text{var}}\left( \hat{u}(M_k | y) \right)}{4 \hat{u}(M_A | y)} - \frac{\widehat{\text{cov}}(\hat{u}(M_A | y), \hat{u}(M_B | y)) }{2 \sqrt{\hat{u}(M_A | y) \hat{u}(M_B | y)}} + \frac{\widehat{\text{var}}\left( \hat{u}(M_B | y) \right)}{4 \hat{u}(M_B | y)}

\subsection{R-squared}
%R-squared, or R2, is a typical measure used to assess how well a model fits data. \cite{gelman_r-squared_2019} propose a Bayesian version of the R2 as the classical R2 might get values larger than 1 for Bayesian regression models. See details from the paper. A nice property of Bayesian R2 is that we get a distribution of R2 values "for free", as it is computed using posterior predictive mean values of the model. This means that we can quantify the uncertainty of the estimator easily.

%If (Bayesian) R2 is computed from the same data that was used to fit the model, it will give an overestimate of the predictive performance on a new, unobserved data. As often we don't have independent test data, we can use cross-validation to estimate the out-of-sample behavior of the R2. \cite{vehtari_practical_2016} propose an efficient and stable method for leave-one-out cross-validation using Pareto smoothed importance sampling. In the paper, log predictive density is used as the utility describing the predictive performance, but the method can easily be extended for other utilities as well, such as R2.

%After computing LOO-R2 estimate, we want to quantify the uncertainty of the estimator. The uncertainty in LOO-R2 comes from not knowing the future data distribution \citep{vehtari_survey_2012}. One way to do it is to use Bayesian bootstrap \citep{rubin_bayesian_1981}. However, this report describes how to quantify the uncertainty using an analytical Taylor approximation approach.

R-squared, or R2, is a typical measure used to assess how well a model fits data. Intuitively speaking is the proportion of the variance in the data a model can explain. 
\\ \\
\textbf{SOME THOUGHTS: In the bayesian version of R2 we propagate the uncertainty from our parameter estimates into the predictions and from there into the Bayesian-R2 estimator. In the PSIS-LOO version of the R2, we "loose" the parameter uncertainty to the importance sampling, and quantify the uncertainty by generating (Bayesian) bootstrap samples of the residuals (y - predictions) and data $y$. So these uncertainty estimates seem to measure different uncertainty.}
\\ \\

As with RMSE, we can interpret R2 as a function of two random variables and utilze the Taylor trick to approximate the variance of the R2 estimator.

LOO-R2 is defined as
\begin{align}
\text{R2}_{loo} = 1 - \frac{\text{var}(\hat{e}_{loo}) }{ \text{var}(y)} \label{loor2}
\end{align}

where $\hat{e}_{loo} = y - \hat{y}_{loo}$. Note that the nominator and denominator of the second term in \eqref{loor2} can be interpreted as the mean squared error of the LOO predictions and mean squared error of predicting the data with its mean, respectively. So we write \eqref{loor2} as 
\begin{align}
    \text{R2}_{loo} = 1 - \frac{\text{MSE}_{\hat{e}} }{ \text{MSE}_y} \label{mser2}
\end{align}

We can then compute the estimator for the variance of both using the same approach as in \cite{sivula_uncertainty_2022} and \cite{vehtari_practical_2016}:
\begin{align}
    \text{var}(\text{MSE}_{\hat{e}}) &= \frac{1}{n (n-1)} \sum_{i = 1}^n \left( \hat{e}_{loo, i}^2 - \text{MSE}_{\hat{e}} \right)^2 \label{vare}
\end{align}
and
\begin{align}
    \text{var}(\text{MSE}_y) &= \frac{1}{n (n-1)} \sum_{i = 1}^n \left( (y_i - \hat{y})^2 -\text{MSE}_y \right)^2 \label{vary},
\end{align}
where $\bar{y}$ is the sample mean of observations $y$. 

To utilize the Taylor approximation, we need to compute partial derivatives of function $f(x,y) = 1 - \frac{x}{y}$. With a simple calculus, we get
\begin{align}
    \frac{\partial}{\partial x}f(x,y) = -\frac{1}{y} \\
    \frac{\partial}{\partial y}f(x,y) = \frac{x}{y^2}.
\end{align}

Substituting these into \eqref{eq:varapprox2d} yields
\begin{align}
    \text{var}(f(X, Y) \approx \frac{1}{\mu_Y^2} \left( \text{var}(X) - 2 \frac{\mu_X}{\mu_Y} \text{cov}(X,Y) + \left( \frac{\mu_X}{\mu_Y} \right)^2 \text{var}(Y) \right) \label{ratiovar}.
\end{align}

 To use this expression for the mean squared errors, we also need the covariance between $\text{MSE}_{\hat{e}}$ and $\text{MSE}_y$. This can be estimated in a similar way as the variances:
 \begin{align}
     \text{cov}(\text{MSE}_{\hat{e}}, \text{MSE}_{y} ) = \frac{1}{n (n -1 )} \sum_{i = 1}^n \left( \hat{e}_{loo, i}^2 - \text{MSE}_{\hat{e}} \right) \left( (y_i - \hat{y})^2 -\text{MSE}_y \right) \label{cov}.
 \end{align}
 
 Putting all pieces together, variance, and consequently the standard error, of LOO-R2 estimator can then be approximated by letting $\mu_X = \text{MSE}_{\hat{e}}$ and $\mu_Y = \text{MSE}_y$ and then substituting with \eqref{vare}, \eqref{vary} and \eqref{cov} into \eqref{ratiovar}:
 \begin{align}
     \text{var}(\text{R2}_{loo}) &= \frac{1}{\text{MSE}_y^2} \left( \text{var}(\text{MSE}_{\hat{e}}) - 2 \frac{\text{MSE}_{\hat{e}}}{\text{MSE}_y} \text{cov}(\text{MSE}_{\hat{e}}, \text{MSE}_{y} ) +  \left( \frac{\text{MSE}_{\hat{e}}}{\text{MSE}_y} \right)^2 \text{var}(\text{MSE}_y) \right) \label{eq:var-loo-r2}.
 \end{align}
 
\section{Simulation experiments}
We use simple simulation experiments to illustrate the behaviour of the proposed estimators for the variance. These simulation are by no means exhaustive, and more elaborate experiments are needed to verify the validity of the Taylor approximation method. We study the properties of the Taylor approximation of the variance of the estimator, and Taylor approximation of the variance of the difference when the utility is either RMSE or R-squared.

We consider simple data generating  mechanism in which we vary the sample size $n \in \{20, 50, 100, 200 \}$ and number of predictors $p \in \{ 2, 3, 5 \}$.
\begin{equation*}
    \begin{aligned}
    y_i &\sim N(\beta^T x_i, \sigma^2) \\
    x_i &\sim N(0, 1) \\
    \beta &\sim N(0, 1)
    \end{aligned}
\end{equation*}
We then with two models $M_A$ and $M_B$ with one and two predictors respectively. Hence for the cases in which $p \neq 2$ both of the models are miss-specified. Then we compute the variance of the estimator for \eqref{eq:true-utility} using Bayesian bootstrap and the proposed Taylor approximation. We only report the variance estimator for the larger model $M_B$. We also compute the variance estimator of the difference in utilities \eqref{eq:true-diff}. For each pair of $(n, p)$, we repeat the procedure for 100 times.

\subsection{RMSE}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{figures/rmse.pdf}
    \caption{Comparison of Taylor (x-axis) and Bayesian bootstrap (y-axis) approximations. Left panel shows the variance estimator for the RMSE estimator and right panel the variance estimator of the RMSE difference.}
    \label{fig:rmse-plot}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{figures/loo_rmse.pdf}
    \caption{LOO RMSE}
    \label{fig:loo-rmse-plot}
\end{figure}


\subsection{LOO-R2}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{figures/r2.pdf}
    \caption{R2}
    \label{fig:r2-plot}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{figures/loo_r2.pdf}
    \caption{Loo R2}
    \label{fig:loo-r2-plot}
\end{figure}

\newpage
\bibliographystyle{plainnat}
\bibliography{references.bib}

\end{document}