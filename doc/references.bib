
@article{sivula_uncertainty_2022,
	title = {Uncertainty in {Bayesian} {Leave}-{One}-{Out} {Cross}-{Validation} {Based} {Model} {Comparison}},
	url = {http://arxiv.org/abs/2008.10296},
	abstract = {Leave-one-out cross-validation (LOO-CV) is a popular method for comparing Bayesian models based on their estimated predictive performance on new, unseen, data. As leave-one-out cross-validation is based on finite observed data, there is uncertainty about the expected predictive performance on new data. By modeling this uncertainty when comparing two models, we can compute the probability that one model has a better predictive performance than the other. Modeling this uncertainty well is not trivial, and for example, it is known that the commonly used standard error estimate is often too small. We study the properties of the Bayesian LOO-CV estimator and the related uncertainty estimates when comparing two models. We provide new results of the properties both theoretically in the linear regression case and empirically for multiple different models and discuss the challenges of modeling the uncertainty. We show that problematic cases include: comparing models with similar predictions, misspecified models, and small data. In these cases, there is a weak connection in the skewness of the individual leave-one-out terms and the distribution of the error of the Bayesian LOO-CV estimator. We show that it is possible that the problematic skewness of the error distribution, which occurs when the models make similar predictions, does not fade away when the data size grows to infinity in certain situations. Based on the results, we also provide practical recommendations for the users of Bayesian LOO-CV for model comparison.},
	urldate = {2022-04-25},
	journal = {arXiv:2008.10296 [stat]},
	author = {Sivula, Tuomas and Magnusson, Måns and Matamoros, Asael Alonzo and Vehtari, Aki},
	month = mar,
	year = {2022},
	note = {arXiv: 2008.10296},
	keywords = {Statistics - Methodology},
	annote = {Comment: 97 pages, 24 figures. Update 2022-03-17: Adding clarifications and experiments},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/HP5KRRYE/Sivula et al. - 2022 - Uncertainty in Bayesian Leave-One-Out Cross-Valida.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/8962VBIR/2008.html:text/html},
}

@article{yao_using_2018,
	title = {Using stacking to average {Bayesian} predictive distributions},
	volume = {13},
	issn = {1936-0975},
	url = {http://arxiv.org/abs/1704.02030},
	doi = {10.1214/17-BA1091},
	abstract = {The widely recommended procedure of Bayesian model averaging is flawed in the M-open setting in which the true data-generating process is not one of the candidate models being fit. We take the idea of stacking from the point estimation literature and generalize to the combination of predictive distributions, extending the utility function to any proper scoring rule, using Pareto smoothed importance sampling to efficiently compute the required leave-one-out posterior distributions and regularization to get more stability. We compare stacking of predictive distributions to several alternatives: stacking of means, Bayesian model averaging (BMA), pseudo-BMA using AIC-type weighting, and a variant of pseudo-BMA that is stabilized using the Bayesian bootstrap. Based on simulations and real-data applications, we recommend stacking of predictive distributions, with BB-pseudo-BMA as an approximate alternative when computation cost is an issue.},
	number = {3},
	urldate = {2022-04-25},
	journal = {Bayesian Analysis},
	author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
	month = sep,
	year = {2018},
	note = {arXiv: 1704.02030},
	keywords = {Statistics - Methodology, Statistics - Computation},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/52I54UT6/Yao et al. - 2018 - Using stacking to average Bayesian predictive dist.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/UIVVA5QL/1704.html:text/html},
}

@article{yao_bayesian_2021,
	title = {Bayesian {Hierarchical} {Stacking}: {Some} {Models} {Are} ({Somewhere}) {Useful}},
	volume = {-1},
	issn = {1936-0975, 1931-6690},
	shorttitle = {Bayesian {Hierarchical} {Stacking}},
	url = {https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Bayesian-Hierarchical-Stacking-Some-Models-Are-Somewhere-Useful/10.1214/21-BA1287.full},
	doi = {10.1214/21-BA1287},
	abstract = {Stacking is a widely used model averaging technique that asymptotically yields optimal predictions among linear averages. We show that stacking is most effective when model predictive performance is heterogeneous in inputs, and we can further improve the stacked mixture with a hierarchical model. We generalize stacking to Bayesian hierarchical stacking. The model weights are varying as a function of data, partially-pooled, and inferred using Bayesian inference. We further incorporate discrete and continuous inputs, other structured priors, and time series and longitudinal data. To verify the performance gain of the proposed method, we derive theory bounds, and demonstrate on several applied problems.},
	number = {-1},
	urldate = {2022-04-25},
	journal = {Bayesian Analysis},
	author = {Yao, Yuling and Pirš, Gregor and Vehtari, Aki and Gelman, Andrew},
	month = jan,
	year = {2021},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Bayesian hierarchical modeling, conditional prediction, covariate shift, model averaging, prior construction, stacking},
	pages = {1--29},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/YJ8U2SIH/Yao et al. - 2021 - Bayesian Hierarchical Stacking Some Models Are (S.pdf:application/pdf;Snapshot:/Users/leevi/Zotero/storage/E5Z7J8TR/21-BA1287.html:text/html},
}

@article{vehtari_survey_2012,
	title = {A survey of {Bayesian} predictive methods for model assessment, selection and comparison},
	volume = {6},
	issn = {1935-7516},
	url = {https://projecteuclid.org/journals/statistics-surveys/volume-6/issue-none/A-survey-of-Bayesian-predictive-methods-for-model-assessment-selection/10.1214/12-SS102.full},
	doi = {10.1214/12-SS102},
	abstract = {To date, several methods exist in the statistical literature for model assessment, which purport themselves specifically as Bayesian predictive methods. The decision theoretic assumptions on which these methods are based are not always clearly stated in the original articles, however. The aim of this survey is to provide a unified review of Bayesian predictive model assessment and selection methods, and of methods closely related to them. We review the various assumptions that are made in this context and discuss the connections between different approaches, with an emphasis on how each method approximates the expected utility of using a Bayesian model for the purpose of predicting future data.},
	number = {none},
	urldate = {2022-04-25},
	journal = {Statistics Surveys},
	author = {Vehtari, Aki and Ojanen, Janne},
	month = jan,
	year = {2012},
	note = {Publisher: Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist., and the Statist. Soc. Canada},
	keywords = {62-02, 62C10, Bayesian, cross-validation, decision theory, Expected utility, information criteria, model assessment, Model selection, predictive},
	pages = {142--228},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/LS5BP5DF/Vehtari and Ojanen - 2012 - A survey of Bayesian predictive methods for model .pdf:application/pdf;Snapshot:/Users/leevi/Zotero/storage/4GQRIE5H/12-SS102.html:text/html},
}

@article{piironen_comparison_2017,
	title = {Comparison of {Bayesian} predictive methods for model selection},
	volume = {27},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-016-9649-y},
	doi = {10.1007/s11222-016-9649-y},
	abstract = {The goal of this paper is to compare several widely used Bayesian model selection methods in practical model selection problems, highlight their differences and give recommendations about the preferred approaches. We focus on the variable subset selection for regression and classification and perform several numerical experiments using both simulated and real world data. The results show that the optimization of a utility estimate such as the cross-validation (CV) score is liable to finding overfitted models due to relatively high variance in the utility estimates when the data is scarce. This can also lead to substantial selection induced bias and optimism in the performance evaluation for the selected model. From a predictive viewpoint, best results are obtained by accounting for model uncertainty by forming the full encompassing model, such as the Bayesian model averaging solution over the candidate models. If the encompassing model is too complex, it can be robustly simplified by the projection method, in which the information of the full model is projected onto the submodels. This approach is substantially less prone to overfitting than selection based on CV-score. Overall, the projection method appears to outperform also the maximum a posteriori model and the selection of the most probable variables. The study also demonstrates that the model selection can greatly benefit from using cross-validation outside the searching process both for guiding the model size selection and assessing the predictive performance of the finally selected model.},
	language = {en},
	number = {3},
	urldate = {2022-04-25},
	journal = {Statistics and Computing},
	author = {Piironen, Juho and Vehtari, Aki},
	month = may,
	year = {2017},
	keywords = {Bayesian model selection, Cross-validation, Projection, Reference model, Selection bias},
	pages = {711--735},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/LPW5SBY4/Piironen and Vehtari - 2017 - Comparison of Bayesian predictive methods for mode.pdf:application/pdf},
}

@article{piironen_projective_2020,
	title = {Projective inference in high-dimensional problems: {Prediction} and feature selection},
	volume = {14},
	issn = {1935-7524, 1935-7524},
	shorttitle = {Projective inference in high-dimensional problems},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-14/issue-1/Projective-inference-in-high-dimensional-problems--Prediction-and-feature/10.1214/20-EJS1711.full},
	doi = {10.1214/20-EJS1711},
	abstract = {This paper reviews predictive inference and feature selection for generalized linear models with scarce but high-dimensional data. We demonstrate that in many cases one can benefit from a decision theoretically justified two-stage approach: first, construct a possibly non-sparse model that predicts well, and then find a minimal subset of features that characterize the predictions. The model built in the first step is referred to as the reference model and the operation during the latter step as predictive projection. The key characteristic of this approach is that it finds an excellent tradeoff between sparsity and predictive accuracy, and the gain comes from utilizing all available information including prior and that coming from the left out features. We review several methods that follow this principle and provide novel methodological contributions. We present a new projection technique that unifies two existing techniques and is both accurate and fast to compute. We also propose a way of evaluating the feature selection process using fast leave-one-out cross-validation that allows for easy and intuitive model size selection. Furthermore, we prove a theorem that helps to understand the conditions under which the projective approach could be beneficial. The key ideas are illustrated via several experiments using simulated and real world data.},
	number = {1},
	urldate = {2022-04-25},
	journal = {Electronic Journal of Statistics},
	author = {Piironen, Juho and Paasiniemi, Markus and Vehtari, Aki},
	month = jan,
	year = {2020},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
	keywords = {62F07, 62F15, 62J12, Feature selection, Post-selection inference, prediction, projection, Sparsity},
	pages = {2155--2197},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/2MUZMFU8/Piironen et al. - 2020 - Projective inference in high-dimensional problems.pdf:application/pdf;Snapshot:/Users/leevi/Zotero/storage/RPNSC94Q/20-EJS1711.html:text/html},
}

@misc{noauthor_gaussian_nodate,
	title = {Gaussian {Processes} for {Machine} {Learning}: {Book} webpage},
	url = {http://gaussianprocess.org/gpml/},
	urldate = {2022-04-25},
	file = {Gaussian Processes for Machine Learning\: Book webpage:/Users/leevi/Zotero/storage/2BXXUYXA/gpml.html:text/html},
}

@book{rasmussen_gaussian_2006,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {Gaussian processes for machine learning},
	isbn = {978-0-262-18253-9},
	language = {en},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2006},
	note = {OCLC: ocm61285753},
	keywords = {Data processing, Gaussian processes, Machine learning, Mathematical models},
	file = {Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf:/Users/leevi/Zotero/storage/UG2Y8KE6/Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf:application/pdf},
}

@article{riutort-mayol_practical_2022,
	title = {Practical {Hilbert} space approximate {Bayesian} {Gaussian} processes for probabilistic programming},
	url = {http://arxiv.org/abs/2004.11408},
	abstract = {Gaussian processes are powerful non-parametric probabilistic models for stochastic functions. However, the direct implementation entails a complexity that is computationally intractable when the number of observations is large, especially when estimated with fully Bayesian methods such as Markov chain Monte Carlo. In this paper, we focus on a low-rank approximate Bayesian Gaussian processes, based on a basis function approximation via Laplace eigenfunctions for stationary covariance functions. The main contribution of this paper is a detailed analysis of the performance, and practical recommendations for how to select the number of basis functions and the boundary factor. Intuitive visualizations and recommendations, make it easier for users to improve approximation accuracy and computational performance. We also propose diagnostics for checking that the number of basis functions and the boundary factor are adequate given the data. The approach is simple and exhibits an attractive computational complexity due to its linear structure, and it is easy to implement in probabilistic programming frameworks. Several illustrative examples of the performance and applicability of the method in the probabilistic programming language Stan are presented together with the underlying Stan model code.},
	urldate = {2022-04-25},
	journal = {arXiv:2004.11408 [stat]},
	author = {Riutort-Mayol, Gabriel and Bürkner, Paul-Christian and Andersen, Michael R. and Solin, Arno and Vehtari, Aki},
	month = mar,
	year = {2022},
	note = {arXiv: 2004.11408},
	keywords = {Statistics - Methodology, Statistics - Computation, Gaussian processes},
	annote = {Comment: 27 pages, 18 figures},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/24DEFXVC/Riutort-Mayol et al. - 2022 - Practical Hilbert space approximate Bayesian Gauss.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/RBAP9XUQ/2004.html:text/html},
}

@article{sailynoja_graphical_2021,
	title = {Graphical {Test} for {Discrete} {Uniformity} and its {Applications} in {Goodness} of {Fit} {Evaluation} and {Multiple} {Sample} {Comparison}},
	url = {http://arxiv.org/abs/2103.10522},
	abstract = {Assessing goodness of fit to a given distribution plays an important role in computational statistics. The Probability integral transformation (PIT) can be used to convert the question of whether a given sample originates from a reference distribution into a problem of testing for uniformity. We present new simulation and optimization based methods to obtain simultaneous confidence bands for the whole empirical cumulative distribution function (ECDF) of the PIT values under the assumption of uniformity. Simultaneous confidence bands correspond to such confidence intervals at each point that jointly satisfy a desired coverage. These methods can also be applied in cases where the reference distribution is represented only by a finite sample. The confidence bands provide an intuitive ECDF-based graphical test for uniformity, which also provides useful information on the quality of the discrepancy. We further extend the simulation and optimization methods to determine simultaneous confidence bands for testing whether multiple samples come from the same underlying distribution. This multiple sample comparison test is especially useful in Markov chain Monte Carlo convergence diagnostics. We provide numerical experiments to assess the properties of the tests using both simulated and real world data and give recommendations on their practical application in computational statistics workflows.},
	urldate = {2022-04-26},
	journal = {arXiv:2103.10522 [stat]},
	author = {Säilynoja, Teemu and Bürkner, Paul-Christian and Vehtari, Aki},
	month = nov,
	year = {2021},
	note = {arXiv: 2103.10522},
	keywords = {Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/TLFQ3THP/Säilynoja et al. - 2021 - Graphical Test for Discrete Uniformity and its App.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/2J4JRHKF/2103.html:text/html},
}

@article{sivula_unbiased_2022,
	title = {Unbiased estimator for the variance of the leave-one-out cross-validation estimator for a {Bayesian} normal model with fixed variance},
	url = {http://arxiv.org/abs/2008.10859},
	abstract = {When evaluating and comparing models using leave-one-out cross-validation (LOO-CV), the uncertainty of the estimate is typically assessed using the variance of the sampling distribution. Considering the uncertainty is important, as the variability of the estimate can be high in some cases. An important result by Bengio and Grandvalet (2004) states that no general unbiased variance estimator can be constructed, that would apply for any utility or loss measure and any model. We show that it is possible to construct an unbiased estimator considering a specific predictive performance measure and model. We demonstrate an unbiased sampling distribution variance estimator for the Bayesian normal model with fixed model variance using the expected log pointwise predictive density (elpd) utility score. This example demonstrates that it is possible to obtain improved, problem-specific, unbiased estimators for assessing the uncertainty in LOO-CV estimation.},
	urldate = {2022-04-26},
	journal = {arXiv:2008.10859 [stat]},
	author = {Sivula, Tuomas and Magnusson, Måns and Vehtari, Aki},
	month = feb,
	year = {2022},
	note = {arXiv: 2008.10859},
	keywords = {Statistics - Methodology},
	annote = {Comment: 21 pages, 1 figure. Communications in Statistics - Theory and Methods (2022)},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/T7Q49KWE/Sivula et al. - 2022 - Unbiased estimator for the variance of the leave-o.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/I7FRZV9R/2008.html:text/html},
}

@article{vehtari_practical_2016,
	title = {Practical {Bayesian} model evaluation using leave-one-out cross-validation and {WAIC}},
	url = {http://arxiv.org/abs/1507.04544},
	doi = {10.1007/s11222-016-9696-4},
	abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparing of predictive errors between two models. We implement the computations in an R package called 'loo' and demonstrate using models fit with the Bayesian inference package Stan.},
	urldate = {2022-04-26},
	journal = {arXiv:1507.04544 [stat]},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	month = sep,
	year = {2016},
	note = {arXiv: 1507.04544},
	keywords = {Statistics - Methodology, Statistics - Computation},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/RHH4VP2Q/Vehtari et al. - 2016 - Practical Bayesian model evaluation using leave-on.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/QFH2LEZS/1507.html:text/html},
}

@article{rubin_bayesian_1981,
	title = {The {Bayesian} {Bootstrap}},
	volume = {9},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-9/issue-1/The-Bayesian-Bootstrap/10.1214/aos/1176345338.full},
	doi = {10.1214/aos/1176345338},
	abstract = {The Bayesian bootstrap is the Bayesian analogue of the bootstrap. Instead of simulating the sampling distribution of a statistic estimating a parameter, the Bayesian bootstrap simulates the posterior distribution of the parameter; operationally and inferentially the methods are quite similar. Because both methods of drawing inferences are based on somewhat peculiar model assumptions and the resulting inferences are generally sensitive to these assumptions, neither method should be applied without some consideration of the reasonableness of these model assumptions. In this sense, neither method is a true bootstrap procedure yielding inferences unaided by external assumptions.},
	number = {1},
	urldate = {2022-04-28},
	journal = {The Annals of Statistics},
	author = {Rubin, Donald B.},
	month = jan,
	year = {1981},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62F15, 62A15, 62G05, Dirichlet, jackknife, Model-free inference},
	pages = {130--134},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/72G3LYDC/Rubin - 1981 - The Bayesian Bootstrap.pdf:application/pdf;Snapshot:/Users/leevi/Zotero/storage/PKYY33AM/1176345338.html:text/html},
}

@inproceedings{rasmussen_occam_2000,
	title = {Occam' s {Razor}},
	volume = {13},
	url = {https://papers.nips.cc/paper/2000/hash/0950ca92a4dcf426067cfd2246bb5ff3-Abstract.html},
	abstract = {The Bayesian paradigm apparently only sometimes gives rise to Occam's  Razor;  at  other times  very  large models perform well.  We  give  simple  examples of both kinds of behaviour. The two views are reconciled when  measuring complexity of functions, rather than of the machinery used to  implement them.  We analyze the complexity of functions for some linear  in the parameter models that are  equivalent to  Gaussian Processes, and  always find Occam's Razor at work.},
	urldate = {2022-04-28},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Rasmussen, Carl and Ghahramani, Zoubin},
	year = {2000},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/GRCXYVWI/Rasmussen and Ghahramani - 2000 - Occam' s Razor.pdf:application/pdf},
}

@article{wilson_good_2016,
	title = {Good {Enough} {Practices} in {Scientific} {Computing}},
	url = {http://arxiv.org/abs/1609.00037},
	abstract = {We present a set of computing tools and techniques that every researcher can and should adopt. These recommendations synthesize inspiration from our own work, from the experiences of the thousands of people who have taken part in Software Carpentry and Data Carpentry workshops over the past six years, and from a variety of other guides. Unlike some other guides, our recommendations are aimed specifically at people who are new to research computing.},
	urldate = {2022-04-29},
	journal = {arXiv:1609.00037 [cs]},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = oct,
	year = {2016},
	note = {arXiv: 1609.00037},
	keywords = {Computer Science - Software Engineering},
	annote = {Comment: 19 pages, 1 figure},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/LVQF86XP/Wilson et al. - 2016 - Good Enough Practices in Scientific Computing.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/8VE2YGN9/1609.html:text/html},
}

@article{cook_validation_2006,
	title = {Validation of {Software} for {Bayesian} {Models} {Using} {Posterior} {Quantiles}},
	volume = {15},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/106186006X136976},
	doi = {10.1198/106186006X136976},
	abstract = {This article presents a simulation-based method designed to establish the computational correctness of software developed to fit a specific Bayesian model, capitalizing on properties of Bayesian posterior distributions. We illustrate the validation technique with two examples. The validation method is shown to find errors in software when they exist and, moreover, the validation output can be informative about the nature and location of such errors. We also compare our method with that of an earlier approach.},
	number = {3},
	urldate = {2022-05-02},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Cook, Samantha R and Gelman, Andrew and Rubin, Donald B},
	month = sep,
	year = {2006},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/106186006X136976},
	keywords = {Correction to Cook, Gelman, and Rubin (2006), Gibbs sampler, Hierarchical models, Markov chain Monte Carlo, Posterior distribution},
	pages = {675--692},
	file = {Snapshot:/Users/leevi/Zotero/storage/KFRV4MWE/106186006X136976.html:text/html;Submitted Version:/Users/leevi/Zotero/storage/QIW4U6HM/Cook et al. - 2006 - Validation of Software for Bayesian Models Using P.pdf:application/pdf},
}

@article{talts_validating_2020,
	title = {Validating {Bayesian} {Inference} {Algorithms} with {Simulation}-{Based} {Calibration}},
	url = {http://arxiv.org/abs/1804.06788},
	abstract = {Verifying the correctness of Bayesian computation is challenging. This is especially true for complex models that are common in practice, as these require sophisticated model implementations and algorithms. In this paper we introduce {\textbackslash}emph\{simulation-based calibration\} (SBC), a general procedure for validating inferences from Bayesian algorithms capable of generating posterior samples. This procedure not only identifies inaccurate computation and inconsistencies in model implementations but also provides graphical summaries that can indicate the nature of the problems that arise. We argue that SBC is a critical part of a robust Bayesian workflow, as well as being a useful tool for those developing computational algorithms and statistical software.},
	urldate = {2022-05-02},
	journal = {arXiv:1804.06788 [stat]},
	author = {Talts, Sean and Betancourt, Michael and Simpson, Daniel and Vehtari, Aki and Gelman, Andrew},
	month = oct,
	year = {2020},
	note = {arXiv: 1804.06788},
	keywords = {Statistics - Methodology},
	annote = {Comment: 19 pages, 13 figures},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/UQDDTWR4/Talts et al. - 2020 - Validating Bayesian Inference Algorithms with Simu.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/TK3DAQR2/1804.html:text/html},
}

@article{solin_hilbert_2020,
	title = {Hilbert {Space} {Methods} for {Reduced}-{Rank} {Gaussian} {Process} {Regression}},
	volume = {30},
	issn = {0960-3174, 1573-1375},
	url = {http://arxiv.org/abs/1401.5508},
	doi = {10.1007/s11222-019-09886-w},
	abstract = {This paper proposes a novel scheme for reduced-rank Gaussian process regression. The method is based on an approximate series expansion of the covariance function in terms of an eigenfunction expansion of the Laplace operator in a compact subset of \${\textbackslash}mathbb\{R\}{\textasciicircum}d\$. On this approximate eigenbasis the eigenvalues of the covariance function can be expressed as simple functions of the spectral density of the Gaussian process, which allows the GP inference to be solved under a computational cost scaling as \${\textbackslash}mathcal\{O\}(nm{\textasciicircum}2)\$ (initial) and \${\textbackslash}mathcal\{O\}(m{\textasciicircum}3)\$ (hyperparameter learning) with \$m\$ basis functions and \$n\$ data points. Furthermore, the basis functions are independent of the parameters of the covariance function, which allows for very fast hyperparameter learning. The approach also allows for rigorous error analysis with Hilbert space theory, and we show that the approximation becomes exact when the size of the compact subset and the number of eigenfunctions go to infinity. We also show that the convergence rate of the truncation error is independent of the input dimensionality provided that the differentiability order of the covariance function is increases appropriately, and for the squared exponential covariance function it is always bounded by \$\{{\textbackslash}sim\}1/m\$ regardless of the input dimensionality. The expansion generalizes to Hilbert spaces with an inner product which is defined as an integral over a specified input density. The method is compared to previously proposed methods theoretically and through empirical tests with simulated and real data.},
	number = {2},
	urldate = {2022-05-03},
	journal = {Statistics and Computing},
	author = {Solin, Arno and Särkkä, Simo},
	month = mar,
	year = {2020},
	note = {arXiv: 1401.5508},
	keywords = {Statistics - Machine Learning},
	pages = {419--446},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/CAKS6GZ9/Solin and Särkkä - 2020 - Hilbert Space Methods for Reduced-Rank Gaussian Pr.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/T3YQNE4L/1401.html:text/html},
}

@article{piironen_sparsity_2017,
	title = {Sparsity information and regularization in the horseshoe and other shrinkage priors},
	volume = {11},
	issn = {1935-7524, 1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-11/issue-2/Sparsity-information-and-regularization-in-the-horseshoe-and-other-shrinkage/10.1214/17-EJS1337SI.full},
	doi = {10.1214/17-EJS1337SI},
	abstract = {The horseshoe prior has proven to be a noteworthy alternative for sparse Bayesian estimation, but has previously suffered from two problems. First, there has been no systematic way of specifying a prior for the global shrinkage hyperparameter based on the prior information about the degree of sparsity in the parameter vector. Second, the horseshoe prior has the undesired property that there is no possibility of specifying separately information about sparsity and the amount of regularization for the largest coefficients, which can be problematic with weakly identified parameters, such as the logistic regression coefficients in the case of data separation. This paper proposes solutions to both of these problems. We introduce a concept of effective number of nonzero parameters, show an intuitive way of formulating the prior for the global hyperparameter based on the sparsity assumptions, and argue that the previous default choices are dubious based on their tendency to favor solutions with more unshrunk parameters than we typically expect a priori. Moreover, we introduce a generalization to the horseshoe prior, called the regularized horseshoe, that allows us to specify a minimum level of regularization to the largest values. We show that the new prior can be considered as the continuous counterpart of the spike-and-slab prior with a finite slab width, whereas the original horseshoe resembles the spike-and-slab with an infinitely wide slab. Numerical experiments on synthetic and real world data illustrate the benefit of both of these theoretical advances.},
	number = {2},
	urldate = {2022-05-03},
	journal = {Electronic Journal of Statistics},
	author = {Piironen, Juho and Vehtari, Aki},
	month = jan,
	year = {2017},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
	keywords = {62F15, Bayesian inference, horseshoe prior, shrinkage priors, Sparse estimation},
	pages = {5018--5051},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/C8Q4ZNGP/Piironen and Vehtari - 2017 - Sparsity information and regularization in the hor.pdf:application/pdf},
}

@article{vehtari_pareto_2021,
	title = {Pareto {Smoothed} {Importance} {Sampling}},
	url = {http://arxiv.org/abs/1507.02646},
	abstract = {Importance weighting is a general way to adjust Monte Carlo integration to account for draws from the wrong distribution, but the resulting estimate can be noisy when the importance ratios have a heavy right tail. This routinely occurs when there are aspects of the target distribution that are not well captured by the approximating distribution, in which case more stable estimates can be obtained by modifying extreme importance ratios. We present a new method for stabilizing importance weights using a generalized Pareto distribution fit to the upper tail of the distribution of the simulated importance ratios. The method, which empirically performs better than existing methods for stabilizing importance sampling estimates, includes stabilized effective sample size estimates, Monte Carlo error estimates and convergence diagnostics.},
	urldate = {2022-05-03},
	journal = {arXiv:1507.02646 [stat]},
	author = {Vehtari, Aki and Simpson, Daniel and Gelman, Andrew and Yao, Yuling and Gabry, Jonah},
	month = feb,
	year = {2021},
	note = {arXiv: 1507.02646},
	keywords = {Statistics - Methodology, Statistics - Computation, Statistics - Machine Learning},
	annote = {Comment: Minor revision: fixed some typos and updated references},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/BZ5K4TYN/Vehtari et al. - 2021 - Pareto Smoothed Importance Sampling.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/2PVLDR3Y/1507.html:text/html},
}

@article{kallioinen_detecting_2021,
	title = {Detecting and diagnosing prior and likelihood sensitivity with power-scaling},
	url = {http://arxiv.org/abs/2107.14054},
	abstract = {Determining the sensitivity of the posterior to perturbations of the prior and likelihood is an important part of the Bayesian workflow. We introduce a practical and computationally efficient sensitivity analysis approach that is applicable to a wide range of models, based on power-scaling perturbations. We suggest a diagnostic based on this that can indicate the presence of prior-data conflict or likelihood noninformativity. The approach can be easily included in Bayesian workflows with minimal work by the model builder. We present the implementation of the approach in our new R package priorsense and demonstrate the workflow on case studies of real data.},
	urldate = {2022-05-03},
	journal = {arXiv:2107.14054 [stat]},
	author = {Kallioinen, Noa and Paananen, Topi and Bürkner, Paul-Christian and Vehtari, Aki},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.14054},
	keywords = {Statistics - Methodology},
	annote = {Comment: 21 pages, 10 figures},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/S6AK5ACB/Kallioinen et al. - 2021 - Detecting and diagnosing prior and likelihood sens.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/5PDG9FSF/2107.html:text/html},
}

@article{zhang_bayesian_2020,
	title = {Bayesian {Regression} {Using} a {Prior} on the {Model} {Fit}: {The} {R2}-{D2} {Shrinkage} {Prior}},
	shorttitle = {Bayesian {Regression} {Using} a {Prior} on the {Model} {Fit}},
	url = {http://arxiv.org/abs/1609.00046},
	abstract = {Prior distributions for high-dimensional linear regression require specifying a joint distribution for the unobserved regression coefficients, which is inherently difficult. We instead propose a new class of shrinkage priors for linear regression via specifying a prior first on the model fit, in particular, the coefficient of determination, and then distributing through to the coefficients in a novel way. The proposed method compares favourably to previous approaches in terms of both concentration around the origin and tail behavior, which leads to improved performance both in posterior contraction and in empirical performance. The limiting behavior of the proposed prior is \$1/x\$, both around the origin and in the tails. This behavior is optimal in the sense that it simultaneously lies on the boundary of being an improper prior both in the tails and around the origin. None of the existing shrinkage priors obtain this behavior in both regions simultaneously. We also demonstrate that our proposed prior leads to the same near-minimax posterior contraction rate as the spike-and-slab prior.},
	urldate = {2022-05-04},
	journal = {arXiv:1609.00046 [stat]},
	author = {Zhang, Yan Dora and Naughton, Brian P. and Bondell, Howard D. and Reich, Brian J.},
	month = jul,
	year = {2020},
	note = {arXiv: 1609.00046},
	keywords = {Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/leevi/Zotero/storage/CKWLBX7S/Zhang et al. - 2020 - Bayesian Regression Using a Prior on the Model Fit.pdf:application/pdf;arXiv.org Snapshot:/Users/leevi/Zotero/storage/TICAJ7V8/1609.html:text/html},
}

@article{gelman_prior_2017,
	title = {The {Prior} {Can} {Often} {Only} {Be} {Understood} in the {Context} of the {Likelihood}},
	volume = {19},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/19/10/555},
	doi = {10.3390/e19100555},
	abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys’ priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
	language = {en},
	number = {10},
	urldate = {2022-05-05},
	journal = {Entropy},
	author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
	month = oct,
	year = {2017},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Bayesian inference, default priors, prior distribution},
	pages = {555},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/M5TNN8BV/Gelman et al. - 2017 - The Prior Can Often Only Be Understood in the Cont.pdf:application/pdf;Snapshot:/Users/leevi/Zotero/storage/PXRAMH2M/555.html:text/html},
}

@article{burkner_brms_2017,
	title = {brms: {An} {R} {Package} for {Bayesian} {Multilevel} {Models} {Using} {Stan}},
	volume = {80},
	copyright = {Copyright (c) 2017 Paul-Christian Bürkner},
	issn = {1548-7660},
	shorttitle = {brms},
	url = {https://doi.org/10.18637/jss.v080.i01},
	doi = {10.18637/jss.v080.i01},
	abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit  -  among others  -  linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
	language = {en},
	urldate = {2022-05-09},
	journal = {Journal of Statistical Software},
	author = {Bürkner, Paul-Christian},
	month = aug,
	year = {2017},
	keywords = {R},
	pages = {1--28},
	file = {Full Text:/Users/leevi/Zotero/storage/5PGFAWEJ/Bürkner - 2017 - brms An R Package for Bayesian Multilevel Models .pdf:application/pdf},
}

@article{gronau_tutorial_2017,
	title = {A tutorial on bridge sampling},
	volume = {81},
	issn = {0022-2496},
	url = {https://www.sciencedirect.com/science/article/pii/S0022249617300640},
	doi = {10.1016/j.jmp.2017.09.005},
	abstract = {The marginal likelihood plays an important role in many areas of Bayesian statistics such as parameter estimation, model comparison, and model averaging. In most applications, however, the marginal likelihood is not analytically tractable and must be approximated using numerical methods. Here we provide a tutorial on bridge sampling (Bennett, 1976; Meng \& Wong, 1996), a reliable and relatively straightforward sampling method that allows researchers to obtain the marginal likelihood for models of varying complexity. First, we introduce bridge sampling and three related sampling methods using the beta-binomial model as a running example. We then apply bridge sampling to estimate the marginal likelihood for the Expectancy Valence (EV) model—a popular model for reinforcement learning. Our results indicate that bridge sampling provides accurate estimates for both a single participant and a hierarchical version of the EV model. We conclude that bridge sampling is an attractive method for mathematical psychologists who typically aim to approximate the marginal likelihood for a limited set of possibly high-dimensional models.},
	language = {en},
	urldate = {2022-05-10},
	journal = {Journal of Mathematical Psychology},
	author = {Gronau, Quentin F. and Sarafoglou, Alexandra and Matzke, Dora and Ly, Alexander and Boehm, Udo and Marsman, Maarten and Leslie, David S. and Forster, Jonathan J. and Wagenmakers, Eric-Jan and Steingroever, Helen},
	month = dec,
	year = {2017},
	keywords = {Bayes factor, Hierarchical model, Marginal likelihood, Normalizing constant, Predictive accuracy, Reinforcement learning},
	pages = {80--97},
	file = {ScienceDirect Full Text PDF:/Users/leevi/Zotero/storage/HJCYTZWK/Gronau et al. - 2017 - A tutorial on bridge sampling.pdf:application/pdf;ScienceDirect Snapshot:/Users/leevi/Zotero/storage/AH6ZPEAH/S0022249617300640.html:text/html},
}

@article{gelman_r-squared_2019,
	title = {R-squared for {Bayesian} {Regression} {Models}},
	volume = {73},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2018.1549100},
	doi = {10.1080/00031305.2018.1549100},
	abstract = {The usual definition of R2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian fits, as the numerator can be larger than the denominator. We propose an alternative definition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the expected variance of the errors.},
	number = {3},
	urldate = {2022-05-11},
	journal = {The American Statistician},
	author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
	month = jul,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2018.1549100},
	keywords = {Bayesian methods, R-squared, Regression},
	pages = {307--309},
	file = {Snapshot:/Users/leevi/Zotero/storage/WFCEU2CW/00031305.2018.html:text/html;Submitted Version:/Users/leevi/Zotero/storage/32MJ2WRS/Gelman et al. - 2019 - R-squared for Bayesian Regression Models.pdf:application/pdf},
}

@article{vehtari_bayesian_2002,
	title = {Bayesian {Model} {Assessment} and {Comparison} {Using} {Cross}-{Validation} {Predictive} {Densities}},
	volume = {14},
	doi = {10.1162/08997660260293292},
	abstract = {In this work, we discuss practical methods for the assessment, comparison, and selection of complex hierarchical Bayesian models. A natural way to assess the goodness of the model is to estimate its future predictive capability by estimating expected utilities. Instead of just making a point estimate, it is important to obtain the distribution of the expected utility estimate because it describes the uncertainty in the estimate. The distributions of the expected utility estimates can also be used to compare models, for example, by computing the probability of one model having a better expected utility than some other model. We propose an approach using cross-validation predictive densities to obtain expected utility estimates and Bayesian bootstrap to obtain samples from their distributions. We also discuss the probabilistic assumptions made and properties of two practical cross-validation methods, importance sampling and k-fold cross-validation. As illustrative examples, we use multilayer perceptron neural networks and gaussian processes with Markov chain Monte Carlo sampling in one toy problem and two challenging real-world problems.},
	journal = {Neural computation},
	author = {Vehtari, Aki and Lampinen, Jouko},
	month = nov,
	year = {2002},
	pages = {2439--68},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/T5YVSHP4/Vehtari and Lampinen - 2002 - Bayesian Model Assessment and Comparison Using Cro.pdf:application/pdf},
}

@article{gelman_understanding_2014,
	title = {Understanding predictive information criteria for {Bayesian} models},
	volume = {24},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-013-9416-2},
	doi = {10.1007/s11222-013-9416-2},
	abstract = {We review the Akaike, deviance, and Watanabe-Akaike information criteria from a Bayesian perspective, where the goal is to estimate expected out-of-sample-prediction error using a bias-corrected adjustment of within-sample error. We focus on the choices involved in setting up these measures, and we compare them in three simple examples, one theoretical and two applied. The contribution of this paper is to put all these information criteria into a Bayesian predictive context and to better understand, through small examples, how these methods can apply in practice.},
	language = {en},
	number = {6},
	urldate = {2022-05-19},
	journal = {Statistics and Computing},
	author = {Gelman, Andrew and Hwang, Jessica and Vehtari, Aki},
	month = nov,
	year = {2014},
	keywords = {AIC, Bayes, Cross-validation, DIC, Prediction, WAIC},
	pages = {997--1016},
	file = {Submitted Version:/Users/leevi/Zotero/storage/YF76IFHT/Gelman et al. - 2014 - Understanding predictive information criteria for .pdf:application/pdf},
}

@article{myung_applying_1997,
	title = {Applying {Occam}’s razor in modeling cognition: {A} {Bayesian} approach},
	volume = {4},
	issn = {1531-5320},
	shorttitle = {Applying {Occam}’s razor in modeling cognition},
	url = {https://doi.org/10.3758/BF03210778},
	doi = {10.3758/BF03210778},
	abstract = {In mathematical modeling of cognition, it is important to have well-justified criteria for choosing among differing explanations (i.e., models) of observed data. This paper introduces a Bayesian model selection approach that formalizes Occam’s razor, choosing the simplest model that describes the data well. The choice of a model is carried out by taking into account not only the traditional model selection criteria (i.e., a model’s fit to the data and the number of parameters) but also the extension of the parameter space, and, most importantly, the functional form of the model (i.e., the way in which the parameters are combined in the model’s equation). An advantage of the approach is that it can be applied to the comparison of non-nested models as well as nested ones. Application examples are presented and implications of the results for evaluating models of cognition are discussed.},
	language = {en},
	number = {1},
	urldate = {2022-05-25},
	journal = {Psychonomic Bulletin \& Review},
	author = {Myung, In Jae and Pitt, Mark A.},
	month = mar,
	year = {1997},
	keywords = {Bayesian Information Criterion, Bayesian Method, Bayesian Model Selection, Journal Ofthe American Statistical Association, Marginal Likelihood},
	pages = {79--95},
	file = {Full Text PDF:/Users/leevi/Zotero/storage/QNPTS6VI/Myung and Pitt - 1997 - Applying Occam’s razor in modeling cognition A Ba.pdf:application/pdf},
}

@book{gelman_bayesian_2015,
	address = {New York},
	edition = {3},
	title = {Bayesian {Data} {Analysis}},
	isbn = {978-0-429-11307-9},
	abstract = {Winner of the 2016 De Groot Prize from the International Society for Bayesian AnalysisNow in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied},
	publisher = {Chapman and Hall/CRC},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	month = jul,
	year = {2015},
	doi = {10.1201/b16018},
}
@article{hastings1970monte,
  title={Monte Carlo sampling methods using Markov chains and their applications},
  author={Hastings, W Keith},
  year={1970},
  journal={Biometrika},
  publisher={Oxford University Press}
}
@Misc{rstanarm,
  title = {rstanarm: {Bayesian} applied regression modeling via {Stan}.},
  author = {Ben Goodrich and Jonah Gabry and Imad Ali and Sam Brilleman},
  note = {R package version 2.21.1},
  year = {2020},
  url = {https://mc-stan.org/rstanarm},
}